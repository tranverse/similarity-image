import fitz  # PyMuPDF
import pdfplumber
# import mysql.connector
import re
import os
import time
from datetime import datetime
from tkinter import Tk, filedialog
from PIL import Image, ImageFile
import io
import cv2
import numpy as np

ImageFile.LOAD_TRUNCATED_IMAGES = True

def connect_to_mysql():
    return mysql.connector.connect(
        host='localhost',
        user='root',
        password='123456',
        database='bb2110065'
    )

def extract_doi(text):
    doi_match = re.search(r'10\.\d{4,9}/[-._;()/:A-Z0-9]+', text, re.IGNORECASE)
    return doi_match.group(0) if doi_match else None

def extract_title_by_fontsize(page):
    max_fontsize = 0
    title_lines = []
    for obj in page.extract_words(use_text_flow=True, extra_attrs=["size"]):
        if obj["size"] > max_fontsize:
            max_fontsize = obj["size"]
    for obj in page.extract_words(use_text_flow=True, extra_attrs=["size"]):
        if abs(obj["size"] - max_fontsize) < 0.5:
            title_lines.append(obj["text"])
    return " ".join(title_lines).strip() if title_lines else "KhÃ´ng rÃµ tiÃªu Ä‘á»"

def extract_authors_and_date(text):
    date_match = re.search(r"(Duyá»‡t Ä‘Äƒng|NgÃ y cháº¥p nháº­n|Accepted).*?:?\s*(\d{1,2}/\d{1,2}/\d{4})", text)
    approved_date = date_match.group(2) if date_match else "KhÃ´ng rÃµ ngÃ y"
    author_match = re.search(r"\n(.+?)\s*\*", text)
    authors = author_match.group(1).strip() if author_match else "KhÃ´ng rÃµ tÃ¡c giáº£"
    authors = re.sub(r'[\d*]+', '', authors).strip()
    return authors, approved_date

def is_image_too_small(image_bytes):
    try:
        image = Image.open(io.BytesIO(image_bytes))
        return image.size[0] < 100 or image.size[1] < 100
    except Exception:
        return True

def is_black_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return np.sum(gray < 30) / gray.size > 0.9

def is_white_image(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    return np.sum(gray > 245) / gray.size > 0.99

def check_and_repair_image(image_bytes):
    try:
        np_img = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(np_img, cv2.IMREAD_COLOR)
        if image is None or image.size == 0:
            return None, "decode_failed"
        if is_image_too_small(image_bytes):
            return None, "too_small"
        if is_black_image(image):
            return None, "too_black"
        if is_white_image(image):
            return None, "too_white"
        repaired_img_bytes = cv2.imencode('.png', image)[1]
        return repaired_img_bytes.tobytes(), "viewable"
    except Exception:
        return None, "error"

def save_image(image_bytes, img_filename):
    try:
        with open(img_filename, "wb") as img_file:
            img_file.write(image_bytes)
        return True
    except Exception:
        return False

def extract_images_and_captions(pdf_path, output_folder):
    # conn = connect_to_mysql()
    # cursor = conn.cursor()
    total_extracted = 0
    viewable = 0
    extraction_date = datetime.now()
    try:
        doc = fitz.open(pdf_path)
        pdf_filename = os.path.splitext(os.path.basename(pdf_path))[0]
        real_pages = {}
        captions_by_page = {}
        doi = title = authors = approved_date = None

        with pdfplumber.open(pdf_path) as pdf:
            for i, page in enumerate(pdf.pages):
                text = page.extract_text()
                if text and i == 0:
                    title = extract_title_by_fontsize(page)
                    authors, approved_date = extract_authors_and_date(text)
                    doi = extract_doi(text)

                # âœ… Láº¥y real_page tá»« 15% cuá»‘i trang
                bottom_texts = [
                    obj for obj in page.extract_words()
                    if obj["top"] > (page.height * 0.85)
                ]

                center_x = page.width / 2
                closest_to_center = None
                min_distance = float("inf")

                for word in bottom_texts:
                    word_center = (word["x0"] + word["x1"]) / 2
                    distance = abs(center_x - word_center)
                    if distance < min_distance and re.fullmatch(r"\d{1,4}", word["text"]):
                        min_distance = distance
                        closest_to_center = word["text"]

                real_page = int(closest_to_center) if closest_to_center else i + 1
                real_pages[i + 1] = real_page

                captions = [line.strip() for line in text.split('\n') if re.search(r'(hÃ¬nh|figure)\s*\d+', line.lower())]
                captions_by_page[i + 1] = captions

        for page_num in range(doc.page_count):
            page = doc.load_page(page_num)
            images = page.get_images(full=True)

            for img_index, img in enumerate(images):
                if page_num == 0 and img_index == 0:
                    continue  # bá» áº£nh Ä‘áº§u tiÃªn

                xref = img[0]
                base_image = doc.extract_image(xref)
                image_bytes = base_image.get("image")
                if not image_bytes:
                    continue
                repaired_image, status = check_and_repair_image(image_bytes)
                if status != "viewable":
                    continue

                os.makedirs(os.path.join(output_folder, 'extracted_images'), exist_ok=True)
                real_page = real_pages.get(page_num + 1, page_num + 1)
                img_name = f"{pdf_filename}_page_{real_page}_img_{img_index + 1}.png"
                img_path = os.path.join(output_folder, 'extracted_images', img_name)

                # Caption logic
                caption_list = captions_by_page.get(page_num + 1, [])
                caption = caption_list[img_index] if img_index < len(caption_list) else "KhÃ´ng cÃ³ chÃº thÃ­ch"
                caption_cleaned = re.sub(r'^(hÃ¬nh|hÃ¬nh áº£nh|figure) \d+[.:]?', '', caption, flags=re.IGNORECASE).strip()

                # LÆ°u áº£nh vÃ  vÃ o DB
                viewable += 1
                # cursor.execute("""
                #     INSERT INTO research (image_field_name, doi, title, caption, page_number, extraction_date, authors, approved_date, language)
                #     VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
                # """, (
                #     img_name,
                #     doi or "No DOI found",
                #     title or "KhÃ´ng rÃµ tiÃªu Ä‘á»",
                #     caption_cleaned,
                #     real_page,
                #     extraction_date,
                #     authors,
                #     approved_date,
                #     'vi'
                # ))

                save_image(repaired_image, img_path)
                total_extracted += 1
        # conn.commit()
    except Exception as e:
        print("Lá»—i:", e)
    # finally:
    #     cursor.close()
    #     conn.close()
    return total_extracted, viewable, 0, time.time()

def select_folder(title):
    root = Tk()
    root.withdraw()
    return filedialog.askdirectory(title=title)

pdf_folder = select_folder("Chá»n thÆ° má»¥c chá»©a PDF")
output_folder = select_folder("Chá»n thÆ° má»¥c lÆ°u áº£nh")

total_extracted = total_viewable = total_time = 0
for file in os.listdir(pdf_folder):
    if file.endswith('.pdf'):
        pdf_path = os.path.join(pdf_folder, file)
        print(f"\nðŸ” Xá»­ lÃ½: {file}")
        start = time.time()
        extracted, viewable, _, _ = extract_images_and_captions(pdf_path, output_folder)
        end = time.time()
        total_extracted += extracted
        total_viewable += viewable
        total_time += (end - start)
        print(f"ðŸ•’ Thá»i gian: {end - start:.2f}s | ðŸ“¸: {extracted} | âœ…: {viewable}")

print("\nðŸ“Š Tá»•ng káº¿t")
print(f"ðŸ–¼ï¸ Tá»•ng áº£nh trÃ­ch xuáº¥t: {total_extracted}")
print(f"âœ… Tá»•ng áº£nh xem Ä‘Æ°á»£c : {total_viewable}")
print(f"â±ï¸ Tá»•ng thá»i gian: {total_time:.2f} giÃ¢y")
